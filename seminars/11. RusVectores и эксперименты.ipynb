{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc706dc4-d38b-47aa-a8f8-5a6827f89a8e",
   "metadata": {},
   "source": [
    "Сегодня мы поговорим о более крупных моделях, которые уже обучены другими. Такие модели намного более стабильны и их результат может быть релевантнее для решения широких задач. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42d5a20-b142-4601-9fd1-ab7a6d310e25",
   "metadata": {},
   "source": [
    "Текущий семинар основан на следующей статье Б. В. Орехова: https://habr.com/ru/articles/326380/  \n",
    "Некоторые ключевые позиции из введения:  \n",
    "1. В какой-то мере реальное словоупотребление могло бы контрастно оттенить потенциальное, которое можно найти в черновиках писателя. Писатель не сразу вдохновенно пишет свой текст от начала до конца, он мучается, выбирает между вариантами, те, что кажутся ему недостаточно выразительными, он вычеркивает и ищет новые.\n",
    "2. Черновики есть не для всех текстов, они отрывочны и читать их сложно. Однако можно провести такой эксперимент: заменить все поддающиеся замене слова на похожие, и читать классический текст параллельно с тем, которого никогда не было, но который мог бы возникнуть в какой-то параллельной вселенной."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aead0d7-8afe-4d66-ad0b-d20da0f58eb9",
   "metadata": {},
   "source": [
    "Здесь мы научимся пользовать готовыми моделями и проведем этот небольшой исследовательский эксперимент. Мы будем пользоваться следующей моделью, подготовленной командой RusVectores (https://rusvectores.org/en/models/):"
   ]
  },
  {
   "attachments": {
    "3360d369-93ef-4815-973f-2047e52cbf9e.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "08b400e4-7726-4d9c-939f-efffb586ed1c",
   "metadata": {},
   "source": [
    "![модель.png](attachment:3360d369-93ef-4815-973f-2047e52cbf9e.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c513165-14be-4bfe-8f32-a857a246bc8d",
   "metadata": {},
   "source": [
    "Чтобы реплицировать эксперимент, нам нужно получить ассоциаты/квазисинонимы для создания квазичерновиков. Мы с вами уже такое делали на основании наших небольших самообученных моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bae29c6-ce1c-4965-9ae2-3e87d50975ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from pymorphy3 import MorphAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "morph = MorphAnalyzer()\n",
    "stopwords_ru = set(stopwords.words('russian'))\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f2594e-d10a-4da4-bff5-d564180750c7",
   "metadata": {},
   "source": [
    "Подгрузим модель из bin-файла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5496e608-f96d-4c91-a063-b08dd9279d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('model.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c464231-58b4-468c-a9f2-23ed58e31e7d",
   "metadata": {},
   "source": [
    "Проверим, что модель работает корректно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19693805-36c8-42bf-ae87-8dac5add87b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.most_similar('запад_NOUN'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acb1945-0db3-416d-bd58-71341ef3b3de",
   "metadata": {},
   "source": [
    "Работает! Теперь сравним, например, результат с И. С.Аксаковым и компанией, а заодно научимся сохранять наши модели, чтобы не обучать их каждый раз заново."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393e3968-b36f-4234-af5d-e2e3a985962e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Slavs/'\n",
    "corpus_tagged = []\n",
    "for filename in tqdm(os.listdir(path)):\n",
    "    with open(path + filename, encoding='utf-8') as txt:\n",
    "        text = txt.read()\n",
    "        text = re.sub(r'\\n', ' ', text)\n",
    "        text = re.sub(r'[^А-Яа-я -]', '', text.lower())\n",
    "        text = [str(morph.parse(token)[0].normal_form) + '_' + str(morph.parse(token)[0].tag.POS) for token in word_tokenize(text) if token not in stopwords_ru and len(token) > 2]\n",
    "        corpus_tagged.append(text)\n",
    "w2v_cbow_tagged = gensim.models.Word2Vec(corpus_tagged, vector_size=300, window=5, min_count=2, sg=0, epochs=5) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a77748-39c5-41b2-94ee-fec2e7a8fd7d",
   "metadata": {},
   "source": [
    "Теперь сохраним обученную модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bca6346-b386-4ca5-a37c-f8e59d5f59f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_cbow_tagged.wv.save_word2vec_format('aksakov_model.bin', binary=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23b022b-5190-486c-bfcf-2dce3036fc63",
   "metadata": {},
   "source": [
    "Выше мы сохранили модель в бинарном формате, который заметно компактнее; он удобен для распространения конечных версий моделей. Можно также сохранять более крупные, но при этом доступные к дообучению файлы следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2667d23d-483f-4a28-8643-49819d1b95da",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_cbow_tagged.save('aksakov_mod.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0fcf0c-a2a5-4d88-8cf1-6ecb5f11b6a3",
   "metadata": {},
   "source": [
    "Такой способ сохраняет не только вектора, но и параметры обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f004af-5c72-4f43-807a-ad32e6dd930f",
   "metadata": {},
   "source": [
    "Проверим, что сохраненная модель рабочая:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd371021-5b53-44e5-ae56-9bbb4444b37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_aks = gensim.models.KeyedVectors.load_word2vec_format('aksakov_model.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d132e9-5275-49b1-9a8b-594e67b60d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_aks.most_similar('запад_NOUN'))\n",
    "print(model.most_similar('запад_NOUN'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e09591-e677-4c9d-a382-b1acce7d2073",
   "metadata": {},
   "source": [
    "И сразу видно качественное отличие очень большой модели и нашей скромной."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee64b0f7-4cfa-4c2d-a70c-decf1ac510fc",
   "metadata": {},
   "source": [
    "Перейдем к созданию псевдочерновиков. Начнем с \"Евгения Онегина\", с которым мы уже много работали."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dd87f2-6020-44dd-bd14-7b65abb23b6c",
   "metadata": {},
   "source": [
    "Для начала просто откроем его:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f35bec-9e5c-4335-8c62-d63ec6912d9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('EugeneOnegin.txt', encoding='utf-8') as txt:\n",
    "    text = txt.read()\n",
    "    text = re.sub(' +', ' ', text) #уберем множественные пробелы, которые используются для отбивки\n",
    "    print(text[63:445])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739477e0-664c-4fd5-b058-2a0fa9862a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('EugeneOnegin.txt', encoding='utf-8') as txt:\n",
    "    text = txt.read()\n",
    "    text = re.sub(' +', ' ', text) #уберем множественные пробелы, которые используются для отбивки\n",
    "    text = text[63:445]\n",
    "    lines = text.split('\\n')\n",
    "    lines_prep = []\n",
    "    for line in lines:\n",
    "        lines_prep.append(' '.join(['_'.join([str(morph.parse(token)[0].normal_form), str(morph.parse(token)[0].tag.POS)]) for token in word_tokenize(line)]))\n",
    "   # text = ' '.join(['_'.join([str(morph.parse(token)[0].normal_form), str(morph.parse(token)[0].tag.POS)]) for token in word_tokenize(text)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf00ad7-6cdd-46fb-833f-8d11a6e04205",
   "metadata": {},
   "source": [
    "Отлично, мы получили первую строфу в начальной форме. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355565d3-930f-4aa8-b513-dd653243b498",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d86ebe2-7560-4715-a3ae-e6b2e109ff37",
   "metadata": {},
   "source": [
    "Теперь надо заменить все возможное на ближайшие ассоциаты. Не имеет смысла менять служебные слова. Пойдем по частям речи. Начнем с существительных и просто посмотрим, что там происходит:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76d67a1-ea77-4042-9298-25d841de8a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in lines_prep:\n",
    "    for token in line.split():\n",
    "        if token[-4:] == 'NOUN':\n",
    "            print(f'{token} из \"Евгения Онегина\" = {model.most_similar(token)[0][0]} \"из векторной модели\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed676a0-1f69-4167-a1d9-03ad0a7883f0",
   "metadata": {},
   "source": [
    "Теперь проведем замены:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b20ddbe-bd62-488c-87af-f084006552b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_nouns_eug = []\n",
    "for line in lines_prep:\n",
    "    line_change = []\n",
    "    for token in line.split():\n",
    "        if token[-4:] == 'NOUN':\n",
    "            line_change.append(model.most_similar(token)[0][0][:-5])\n",
    "        else:\n",
    "            line_change.append(token[:-5])\n",
    "    new_nouns_eug.append(' '.join(line_change))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c94714-7c0f-4547-b1f5-8073a63386d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_new = '\\n'.join(new_nouns_eug)\n",
    "text_new = re.sub('_', '', text_new)\n",
    "text_new = re.sub(r'\\s+([.,!?;:])', r'\\1', text_new) #уберем пробелы\n",
    "print(text_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1317963-83be-4518-bb7b-ef2a307575cc",
   "metadata": {},
   "source": [
    "Восстановим падежные формы. Pymorphy умеет восстанавливать формы с помощью inflect. У нас есть следующие падежи:\n",
    "1. **nomn**,\n",
    "2.  **gent**,\n",
    "3.  **datv**,\n",
    "4.  **accs**,\n",
    "5.  **ablt**,\n",
    "6.  **loct**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e555aa46-10a5-4761-84ce-651e590d3ada",
   "metadata": {},
   "source": [
    "Получается это не самым простым образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a5d3d2-26e4-478f-9ce8-44023e06971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph.parse('племянник')[0].inflect({'accs'}).word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebd8dca-e797-4e84-834c-0bc203a13787",
   "metadata": {},
   "source": [
    "Соберем по оригинальному тексту нужную нам грамматическую информацию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4e60e9-4c67-4e75-ac48-ca2a92424bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns_cases = []\n",
    "for token in word_tokenize(text):\n",
    "    tok_parse = morph.parse(token)[0]\n",
    "    if tok_parse.tag.POS == 'NOUN':\n",
    "        nouns_cases.append(tok_parse.tag.case)\n",
    "print(nouns_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e8b342-3ace-4402-b876-ae83fa031eed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "ind = 0\n",
    "new_text_cased_lst = []\n",
    "for line in text_new.split('\\n'):\n",
    "    new_line = []\n",
    "    for token in word_tokenize(line):\n",
    "        if morph.parse(token)[0].tag.POS == 'NOUN':\n",
    "            print(nouns_cases[counter])\n",
    "            new_line.append(morph.parse(token)[0].inflect({nouns_cases[counter]}).word)\n",
    "            counter += 1\n",
    "            ind += 1\n",
    "        else:\n",
    "            new_line.append(word_tokenize(text)[ind])\n",
    "            ind += 1\n",
    "    new_text_cased_lst.append(' '.join(new_line))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef5bbcd-46cf-403f-ac40-1ecfb2194bac",
   "metadata": {},
   "source": [
    "Насладимся результатом (нам явно не хватило падежей, отсюда ошибка выше):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eb7c3d-1165-4c7a-b8e7-610b2cd99ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text_cased = '\\n'.join(new_text_cased_lst)\n",
    "new_text_cased = re.sub(r'\\s+([.,!?;:])', r'\\1', new_text_cased) \n",
    "print(new_text_cased)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c32e44a-ad06-4a90-b559-5f5867c11fca",
   "metadata": {},
   "source": [
    "Теперь, когда понятен общий принцип, объединим все вместе и оптимизируем алгоритм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7473fdef-ca24-4356-91a1-446f4c7dbb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('EugeneOnegin.txt', encoding='utf-8') as txt:\n",
    "    text = txt.read()\n",
    "    text = re.sub(' +', ' ', text) \n",
    "    text = text[63:445]\n",
    "    lines = text.split('\\n')\n",
    "    lines_prep = []\n",
    "    for line in lines:\n",
    "        new_line = []\n",
    "        for token in word_tokenize(line):\n",
    "            parse_tok = morph.parse(token)[0]\n",
    "            if parse_tok.tag.POS == 'NOUN':\n",
    "                case = parse_tok.tag.case\n",
    "                number = parse_tok.tag.number\n",
    "                new_noun = model.most_similar('_'.join([parse_tok.normal_form, 'NOUN']))[0][0]\n",
    "                new_noun = re.sub('_[A-Z]+', '', new_noun)\n",
    "                new_line.append(morph.parse(new_noun)[0].inflect({case, number}).word)\n",
    "            else:\n",
    "                new_line.append(token)\n",
    "        lines_prep.append(' '.join(new_line))\n",
    "    final_strophe = '\\n'.join(lines_prep)\n",
    "    final_strophe = re.sub(r'\\s+([.,!?;:])', r'\\1', final_strophe) \n",
    "    print(final_strophe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9598fe-c73e-49b1-b760-663effcc6e21",
   "metadata": {},
   "source": [
    "Уже неплохо! Но нам нужно защититься от замен не на ту часть речи, если таковая случится. Для этого нам нужно брать некоторое количество топовых сходств, а не первое, а затем фильтровать. Поменяем чуть-чуть код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3643c8a-7a84-4117-bf42-2491a41bc4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('EugeneOnegin.txt', encoding='utf-8') as txt:\n",
    "    text = txt.read()\n",
    "    text = re.sub(' +', ' ', text) \n",
    "    text = text[63:445]\n",
    "    lines = text.split('\\n')\n",
    "    lines_prep = []\n",
    "    for line in lines:\n",
    "        new_line = []\n",
    "        for token in word_tokenize(line):\n",
    "            parse_tok = morph.parse(token)[0]\n",
    "            if parse_tok.tag.POS == 'NOUN':\n",
    "                case = parse_tok.tag.case\n",
    "                number = parse_tok.tag.number\n",
    "                similar_words = model.most_similar('_'.join([parse_tok.normal_form, 'NOUN']), topn=10)\n",
    "                for sim_word in similar_words:\n",
    "                    if sim_word[0][-4:] == 'NOUN':\n",
    "                        new_noun = re.sub('_[A-Z]+', '', sim_word[0])\n",
    "                        new_line.append(morph.parse(new_noun)[0].inflect({case, number}).word)\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "            else:\n",
    "                new_line.append(token)\n",
    "        lines_prep.append(' '.join(new_line))\n",
    "    final_strophe = '\\n'.join(lines_prep)\n",
    "    final_strophe = re.sub(r'\\s+([.,!?;:])', r'\\1', final_strophe) \n",
    "    print(final_strophe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b7dc3d-2ea2-46ee-a7a5-b1acc7fb7553",
   "metadata": {},
   "source": [
    "Остались нюансы в виде согласования. Можно, конечно, контролировать зависимые прилагательные (желающие могут рискнуть написать такой код), но пока просто добавим контроль, чтобы существительное было того же рода:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619b00e4-35c5-425e-b2cd-c987748d0ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('EugeneOnegin.txt', encoding='utf-8') as txt:\n",
    "    text = txt.read()\n",
    "    text = re.sub(' +', ' ', text) \n",
    "    text = text[63:445]\n",
    "    lines = text.split('\\n')\n",
    "    lines_prep = []\n",
    "    for line in lines:\n",
    "        new_line = []\n",
    "        for token in word_tokenize(line):\n",
    "            parse_tok = morph.parse(token)[0]\n",
    "            if parse_tok.tag.POS == 'NOUN':\n",
    "                case = parse_tok.tag.case\n",
    "                number = parse_tok.tag.number\n",
    "                gender = parse_tok.tag.gender\n",
    "                similar_words = model.most_similar('_'.join([parse_tok.normal_form, 'NOUN']), topn=100)\n",
    "                for sim_word in similar_words:\n",
    "                    if sim_word[0][-4:] == 'NOUN' and morph.parse(sim_word[0][:-5])[0].tag.gender == gender:\n",
    "                        new_noun = re.sub('_[A-Z]+', '', sim_word[0])\n",
    "                        new_line.append(morph.parse(new_noun)[0].inflect({case, number}).word)\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "            else:\n",
    "                new_line.append(token)\n",
    "        lines_prep.append(' '.join(new_line))\n",
    "    final_strophe = '\\n'.join(lines_prep)\n",
    "    final_strophe = re.sub(r'\\s+([.,!?;:])', r'\\1', final_strophe) \n",
    "    print(final_strophe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b50e0d-8fc4-4784-afc2-bc3983208b7c",
   "metadata": {},
   "source": [
    "Посмотрим на сон Татьяны:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8910f3-da1d-4dc1-883e-12e8d7dc69f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dream = '''И страшно ей; и торопливо\n",
    "Татьяна силится бежать:\n",
    "Нельзя никак; нетерпеливо\n",
    "Метаясь, хочет закричать:\n",
    "Не может; дверь толкнул Евгений:\n",
    "И взорам адских привидений\n",
    "Явилась дева; ярый смех\n",
    "Раздался дико; очи всех,\n",
    "Копыты, хоботы кривые,\n",
    "Хвосты хохлатые, клыки,\n",
    "Усы, кровавы языки,\n",
    "Рога и пальцы костяные,\n",
    "Всё указует на нее,\n",
    "И все кричат: мое! мое!\n",
    "'''\n",
    "\n",
    "\n",
    "text = dream\n",
    "text = re.sub(' +', ' ', text) \n",
    "text = text[63:445]\n",
    "lines = text.split('\\n')\n",
    "lines_prep = []\n",
    "for line in lines:\n",
    "    new_line = []\n",
    "    for token in word_tokenize(line):\n",
    "        parse_tok = morph.parse(token)[0]\n",
    "        if parse_tok.tag.POS == 'NOUN':\n",
    "            case = parse_tok.tag.case\n",
    "            number = parse_tok.tag.number\n",
    "            gender = parse_tok.tag.gender\n",
    "            similar_words = model.most_similar('_'.join([parse_tok.normal_form, 'NOUN']), topn=100)\n",
    "            for sim_word in similar_words:\n",
    "                if sim_word[0][-4:] == 'NOUN' and morph.parse(sim_word[0][:-5])[0].tag.gender == gender:\n",
    "                    new_noun = re.sub('_[A-Z]+', '', sim_word[0])\n",
    "                    new_line.append(morph.parse(new_noun)[0].inflect({case, number}).word)\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "        else:\n",
    "            new_line.append(token)\n",
    "    lines_prep.append(' '.join(new_line))\n",
    "final_strophe = '\\n'.join(lines_prep)\n",
    "final_strophe = re.sub(r'\\s+([.,!?;:])', r'\\1', final_strophe) \n",
    "print(final_strophe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1296163f-9b9a-42f1-bb37-87b21c0ce769",
   "metadata": {},
   "source": [
    "Мы столкнулись с ошибкой, так что добавим исключения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f61df3-3269-41ba-9433-192ae5127f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dream = '''И страшно ей; и торопливо\n",
    "Татьяна силится бежать:\n",
    "Нельзя никак; нетерпеливо\n",
    "Метаясь, хочет закричать:\n",
    "Не может; дверь толкнул Евгений:\n",
    "И взорам адских привидений\n",
    "Явилась дева; ярый смех\n",
    "Раздался дико; очи всех,\n",
    "Копыты, хоботы кривые,\n",
    "Хвосты хохлатые, клыки,\n",
    "Усы, кровавы языки,\n",
    "Рога и пальцы костяные,\n",
    "Всё указует на нее,\n",
    "И все кричат: мое! мое!\n",
    "'''\n",
    "\n",
    "text = dream\n",
    "lines = text.split('\\n')\n",
    "lines_prep = []\n",
    "for line in lines:\n",
    "    new_line = []\n",
    "    for token in word_tokenize(line):\n",
    "        parse_tok = morph.parse(token)[0]\n",
    "        if parse_tok.tag.POS == 'NOUN':\n",
    "            case = parse_tok.tag.case\n",
    "            number = parse_tok.tag.number\n",
    "            gender = parse_tok.tag.gender\n",
    "            try:\n",
    "                similar_words = model.most_similar('_'.join([parse_tok.normal_form, 'NOUN']), topn=100)\n",
    "                for sim_word in similar_words:\n",
    "                    if sim_word[0][-4:] == 'NOUN' and morph.parse(sim_word[0][:-5])[0].tag.gender == gender:\n",
    "                        new_noun = re.sub('_[A-Z]+', '', sim_word[0])\n",
    "                        new_line.append(morph.parse(new_noun)[0].inflect({case, number}).word)\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "            except KeyError:\n",
    "                    new_noun = parse_tok.inflect({case, number}).word\n",
    "                    new_line.append(new_noun)\n",
    "\n",
    "        else:\n",
    "            new_line.append(token)\n",
    "    lines_prep.append(' '.join(new_line))\n",
    "final_strophe = '\\n'.join(lines_prep)\n",
    "final_strophe = re.sub(r'\\s+([.,!?;:])', r'\\1', final_strophe) \n",
    "print(final_strophe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607410ec-1533-44c8-a2f3-e09ce2ca77eb",
   "metadata": {},
   "source": [
    "**Задание 1**. Возьмите любые пять  русских пословиц и замените в них существительные. Что получится?  \n",
    "Можно взять здесь: https://ru.wikiquote.org/wiki/%D0%A0%D1%83%D1%81%D1%81%D0%BA%D0%B8%D0%B5_%D0%BF%D0%BE%D1%81%D0%BB%D0%BE%D0%B2%D0%B8%D1%86%D1%8B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e9da18-2561-4548-b994-9139c889f074",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0763f0-c284-4fdc-a46c-62c0d632f1f2",
   "metadata": {},
   "source": [
    "Теперь поработаем с прилагательными: с ними работать приятно, т.к. набор тэгов совпадает с существительными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c52a94d-81f4-4cc2-9060-097f34b948d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('EugeneOnegin.txt', encoding='utf-8') as txt:\n",
    "    text = txt.read()\n",
    "    text = re.sub(' +', ' ', text) \n",
    "    text = text[63:445]\n",
    "    lines = text.split('\\n')\n",
    "lines_prep = []\n",
    "for line in lines:\n",
    "    new_line = []\n",
    "    for token in word_tokenize(line):\n",
    "        parse_tok = morph.parse(token)[0]\n",
    "        if parse_tok.tag.POS in ['ADJF', 'ADJS']:\n",
    "            case = parse_tok.tag.case or 'nomn'\n",
    "            number = parse_tok.tag.number or random.choice(['sing', 'plur'])\n",
    "            gender = parse_tok.tag.gender or random.choice(['neut', 'femn', 'masc'])\n",
    "            tok_for_model = '_'.join([parse_tok.normal_form, 'ADJ'])\n",
    "            if tok_for_model in model:\n",
    "                similar_words = model.most_similar(tok_for_model, topn=10)\n",
    "                for sim_word in similar_words:\n",
    "                    if sim_word[0][-3:] == 'ADJ':\n",
    "                        new_adj = re.sub('_[A-Z]+', '', sim_word[0])\n",
    "                        infl = morph.parse(new_adj)[0].inflect({case, number, gender})\n",
    "                        if infl:\n",
    "                            new_line.append(infl.word)\n",
    "                        else:\n",
    "                            new_line.append(parse_tok.word)\n",
    "                        break \n",
    "\n",
    "\n",
    "                else:\n",
    "                    infl = parse_tok.inflect({case, number, gender})\n",
    "                    new_line.append(infl.word if infl else parse_tok.word)\n",
    "\n",
    "        else:\n",
    "            new_line.append(parse_tok.word)\n",
    "\n",
    "\n",
    "    \n",
    "    lines_prep.append(' '.join(new_line))\n",
    "\n",
    "\n",
    "   \n",
    "final_strophe = '\\n'.join(lines_prep)\n",
    "final_strophe = re.sub(r'\\s+([.,!?;:])', r'\\1', final_strophe) \n",
    "print(final_strophe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23181499-0015-4584-a761-5b3a98d2e161",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''И страшно ей; и торопливо\n",
    "Татьяна силится бежать:\n",
    "Нельзя никак; нетерпеливо\n",
    "Метаясь, хочет закричать:\n",
    "Не может; дверь толкнул Евгений:\n",
    "И взорам адских привидений\n",
    "Явилась дева; ярый смех\n",
    "Раздался дико; очи всех,\n",
    "Копыты, хоботы кривые,\n",
    "Хвосты хохлатые, клыки,\n",
    "Усы, кровавы языки,\n",
    "Рога и пальцы костяные,\n",
    "Всё указует на нее,\n",
    "И все кричат: мое! мое!\n",
    "'''\n",
    "lines = text.split('\\n')\n",
    "lines_prep = []\n",
    "for line in lines:\n",
    "    new_line = []\n",
    "    for token in word_tokenize(line):\n",
    "        parse_tok = morph.parse(token)[0]\n",
    "        if parse_tok.tag.POS in ['ADJF', 'ADJS']:\n",
    "            case = parse_tok.tag.case or 'nomn'\n",
    "            number = parse_tok.tag.number or random.choice(['sing', 'plur'])\n",
    "            gender = parse_tok.tag.gender or random.choice(['neut', 'femn', 'masc'])\n",
    "            tok_for_model = '_'.join([parse_tok.normal_form, 'ADJ'])\n",
    "            if tok_for_model in model:\n",
    "                similar_words = model.most_similar(tok_for_model, topn=10)\n",
    "                for sim_word in similar_words:\n",
    "                    if sim_word[0][-3:] == 'ADJ':\n",
    "                        new_adj = re.sub('_[A-Z]+', '', sim_word[0])\n",
    "                        infl = morph.parse(new_adj)[0].inflect({case, number, gender})\n",
    "                        if infl:\n",
    "                            new_line.append(infl.word)\n",
    "                        else:\n",
    "                            new_line.append(parse_tok.word)\n",
    "                        break \n",
    "\n",
    "                else:\n",
    "                    infl = parse_tok.inflect({case, number, gender})\n",
    "                    new_line.append(infl.word if infl else parse_tok.word)\n",
    "\n",
    "        else:\n",
    "            new_line.append(parse_tok.word)\n",
    "\n",
    "\n",
    "    \n",
    "    lines_prep.append(' '.join(new_line))\n",
    "\n",
    "\n",
    "   \n",
    "final_strophe = '\\n'.join(lines_prep)\n",
    "final_strophe = re.sub(r'\\s+([.,!?;:])', r'\\1', final_strophe) \n",
    "print(final_strophe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a7b5b4-4ba8-488a-a4d7-df2d41471cb2",
   "metadata": {},
   "source": [
    "Теперь наречия, что ещё легче:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9eb9d20-d96f-423b-9a39-66d9d4148ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dream = '''И страшно ей; и торопливо\n",
    "Татьяна силится бежать:\n",
    "Нельзя никак; нетерпеливо\n",
    "Метаясь, хочет закричать:\n",
    "Не может; дверь толкнул Евгений:\n",
    "И взорам адских привидений\n",
    "Явилась дева; ярый смех\n",
    "Раздался дико; очи всех,\n",
    "Копыты, хоботы кривые,\n",
    "Хвосты хохлатые, клыки,\n",
    "Усы, кровавы языки,\n",
    "Рога и пальцы костяные,\n",
    "Всё указует на нее,\n",
    "И все кричат: мое! мое!\n",
    "'''\n",
    "\n",
    "text = dream\n",
    "text = re.sub(' +', ' ', text) \n",
    "lines = text.split('\\n')\n",
    "lines_prep = []\n",
    "for line in lines:\n",
    "    new_line = []\n",
    "    for token in word_tokenize(line):\n",
    "        parse_tok = morph.parse(token)[0]\n",
    "        if parse_tok.tag.POS == 'ADVB':\n",
    "            try:\n",
    "                similar_words = model.most_similar('_'.join([parse_tok.normal_form, 'ADV']), topn=5)\n",
    "                \n",
    "                for sim_word in similar_words:\n",
    "\n",
    "                    if sim_word[0][-3:] == 'ADV':\n",
    "                        new_adv = re.sub('_[A-Z]+', '', sim_word[0])\n",
    "                        new_line.append(new_adv)\n",
    "                        break\n",
    "            except KeyError:\n",
    "                    new_adv = parse_tok.word\n",
    "                    new_line.append(new_adv)\n",
    "        else:\n",
    "            new_line.append(token)    \n",
    "    lines_prep.append(' '.join(new_line))\n",
    "    \n",
    "final_strophe = '\\n'.join(lines_prep)\n",
    "final_strophe = re.sub(r'\\s+([.,!?;:])', r'\\1', final_strophe) \n",
    "print(final_strophe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bf45e5-87f8-4dd5-8c1b-3ab2258ce5e3",
   "metadata": {},
   "source": [
    "И закончим глаголами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f290dec9-c4c4-4998-ba33-9ab1c2c6a44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = dream\n",
    "text = re.sub(' +', ' ', text) \n",
    "lines = text.split('\\n')\n",
    "lines_prep = []\n",
    "for line in lines:\n",
    "    new_line = []\n",
    "    for token in word_tokenize(line):\n",
    "        parse_tok = morph.parse(token)[0]\n",
    "        tense = parse_tok.tag.tense\n",
    "        person = parse_tok.tag.person\n",
    "        if parse_tok.tag.POS in ['VERB', 'INFN']:\n",
    "            try:\n",
    "                sim_verbs = model.most_similar('_'.join([parse_tok.normal_form, 'VERB']), topn=5)\n",
    "                for sim_verb in sim_verbs:\n",
    "                    if sim_verb[0][-4:] == 'VERB':\n",
    "                        new_verb = re.sub('_[A-Z]+', '', sim_verb[0])\n",
    "                        inflect_tags = {'INFN'} if parse_tok.tag.POS == 'INFN' else set()\n",
    "                        if tense and parse_tok.tag.POS != 'INFN':\n",
    "                            inflect_tags.add(tense)\n",
    "                        if person and parse_tok.tag.POS != 'INFN':\n",
    "                            inflect_tags.add(person)\n",
    "                        inflected = morph.parse(new_verb)[0].inflect(inflect_tags)\n",
    "                        verb_infl = inflected.word if inflected else new_verb\n",
    "                        new_line.append(verb_infl)\n",
    "                        break\n",
    "                else:\n",
    "                    new_line.append(parse_tok.word)\n",
    "            except KeyError:\n",
    "                new_line.append(parse_tok.word)\n",
    "        else:\n",
    "            new_line.append(parse_tok.word)\n",
    "    lines_prep.append(' '.join(new_line))\n",
    "final_strophe = '\\n'.join(lines_prep) \n",
    "final_strophe = re.sub(r'\\s+([.,!?;:])', r'\\1', final_strophe) \n",
    "print(final_strophe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1bf22c-1d79-4462-aa84-fce748b1ac7c",
   "metadata": {},
   "source": [
    "Осталось только написать мегафункцию, которая \"испортит\" все части речи. Сделаем же это.  \n",
    "**Задание 2**. Попробуйте объединить весь код так, чтобы получилась единая функция для всех частей речи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eb0f9a-3695-4694-bda7-0bbed124c906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strophe_changer(text):\n",
    "    return final_strophe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162b63cd-9fb4-44c7-a847-41e6ab452e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''И страшно ей; и торопливо\n",
    "Татьяна силится бежать:\n",
    "Нельзя никак; нетерпеливо\n",
    "Метаясь, хочет закричать:\n",
    "Не может; дверь толкнул Евгений:\n",
    "И взорам адских привидений\n",
    "Явилась дева; ярый смех\n",
    "Раздался дико; очи всех,\n",
    "Копыты, хоботы кривые,\n",
    "Хвосты хохлатые, клыки,\n",
    "Усы, кровавы языки,\n",
    "Рога и пальцы костяные,\n",
    "Всё указует на нее,\n",
    "И все кричат: мое! мое!\n",
    "'''\n",
    "print(strophe_changer(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d91b7f-63e3-4797-860f-284c4c227132",
   "metadata": {},
   "source": [
    "**Задание 3.** Перепешите на основании всего того, что есть выше, \"Анну Каренину\" так, как будто её написал Ф. М. Достоевский (или любой другой автор на ваше усмотрение). Обучите модель на основании предложенного корпуса Достоевского."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f9d2d6-465c-4200-a816-fd368f7e87e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
