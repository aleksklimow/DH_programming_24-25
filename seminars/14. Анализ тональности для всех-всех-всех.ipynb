{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a71c6e57-a9f7-4085-abc9-cc1a772f4ed1",
   "metadata": {},
   "source": [
    "**Анализ тональности (сентимент-анализ)** - важный инструмент как индустриальных, так и научных исследований. Вы можете с его помощью оценить как рецепцию нововведений или рекламной кампании, так и отношение, например, к Наполеону Бонапарту в широком корпусе текстов. \n",
    "Существует несколько подходов к оценке тональности в тексте:\n",
    "1. Основанный на лексиконе, т.е. таких списках слов, которые заранее размечены как, например, \"позитивный\" или \"негативный\";\n",
    "2. Классическое машинное обучение: можно построить вектора заранее размеченных текстов, а зачем настроить классификатор (подобно тому, как мы работали со спамом);\n",
    "3. Методы глубокого обучения, например, с помощью BERT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8323c3ae-8c5b-4241-8b0c-2e4502b1228a",
   "metadata": {},
   "source": [
    "Сами подходы к анализу текста тоже могут быть разнообразными: мы можем оценивать текст целиком, а может дробить его на части, исследуя искомый психологизм (например, нагнетание негатива в романе); мы можем находить отдельные сущности или концепции (уже упомянутый Наполеон или разделение на оценку сервиса или еды в отзывах на ресторан)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d0b126-42a3-4cfe-9a57-8c0fe2187140",
   "metadata": {},
   "source": [
    "(Вообще, конечно, это умеют делать современные генеративные модели до определенной степени, но мы все равно научимся основным способам, не подключающим их; тем более что обработка большого массива текстов с их помощью потребует либо API, либо разворачивания своей модели, либо весьма заумного промптинга и немалых усилий). Так оценивает следующий текст Grok:  \n",
    "*Он злобно приподнялся, чувствуя, что весь разбит; кости его болели. На дворе совершенно густой туман и ничего разглядеть нельзя. Час пятый в исходе; проспал! Он встал и надел свою жакетку и пальто, еще сырые. Нащупав в кармане револьвер, он вынул его и поправил капсюль; потом сел, вынул из кармана записную книжку и на заглавном, самом заметном листке, написал крупно несколько строк. Перечитав их, он задумался, облокотясь на стол. Револьвер и записная книжка лежали тут же, у локтя. Проснувшиеся мухи лепились на нетронутую порцию телятины, стоявшую тут же на столе. Он долго смотрел на них и, наконец, свободною правою рукой начал ловить одну муху. Долго истощался он в усилиях, но никак не мог поймать. Наконец, поймав себя на этом интересном занятии, очнулся, вздрогнул, встал и решительно пошел из комнаты. Через минуту он был на улице.*\n",
    "\n",
    "Тональность текста **негативная**.  \n",
    "\n",
    "Обоснование: Текст описывает мрачные, тягостные эмоции и физическое состояние героя (злость, боль, разбитость), а также создает атмосферу безысходности и подавленности через упоминания густого тумана, сырости, револьвера и записной книжки с крупно написанными строками, что намекает на возможные мрачные намерения. Действия героя, такие как бесцельная попытка ловить муху и его внезапное \"очнулся, вздрогнул\", усиливают ощущение внутренней тревоги и отчаяния."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f2f534-2f56-41f0-85f2-140d186d2f13",
   "metadata": {},
   "source": [
    "Однако начнем по порядку. Основанный на **лексиконе** подход прост в применении и не требует мощных вычислений, требует только словаря, вполне уместен в употреблении, хотя и имеет свои недостатки вроде неумения ухватить контекст (например, иронию)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5179201b-09a8-402e-ac7e-64761750a7f5",
   "metadata": {},
   "source": [
    "Основная проблема, конечно, лексикон. Как его собрать? Можно, например, достать какой-то небольшой набор из word2vec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd2046d-4b6d-4c2e-8ffd-538e4d0cf306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from pymorphy3 import MorphAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "morph = MorphAnalyzer()\n",
    "stopwords_ru = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4562f792-b394-4a3e-922a-70e797f8394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('model.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc351c17-901f-46f7-9576-ada04838f764",
   "metadata": {},
   "source": [
    "Соберем все похожие слова на \"негативный\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50b160e-8a15-4343-8e79-453dd22ce031",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_adj_sim = model.most_similar('негативный_ADJ', topn=100)\n",
    "neg_adj = [sim for sim in neg_adj_sim if sim[0].endswith('ADJ') and sim[1] > 0.42]\n",
    "neg_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cc47c5-20e3-41fb-a6ff-9b3a03f16c20",
   "metadata": {},
   "source": [
    "Выглядит даже неплохо! Кроме того, что там есть несколько неудачных слов (*позитивный, положительный*), которые мы можем элиминировать: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e854f8cc-3b9f-45cf-a9da-6d4855060623",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_adj_fin = [adj[0][:-4] for adj in neg_adj if adj[0][:-4] not in ['позитивный', 'положительный']]\n",
    "print(neg_adj_fin)\n",
    "print(len(neg_adj_fin))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38737812-c559-4ef8-995c-53068ee50dfb",
   "metadata": {},
   "source": [
    "Проделаем то же самое с позитивным:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b0f431-f2ae-460e-92be-9586cfb75120",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_adj_sim = model.most_similar('позитивный_ADJ', topn=100)\n",
    "pos_adj = [sim for sim in pos_adj_sim if sim[0].endswith('ADJ') and sim[1] > 0.42]\n",
    "pos_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047ef9db-a91a-492d-a8c7-48876df25e38",
   "metadata": {},
   "source": [
    "Здесь явно лишние: негативный, отрицательный, субъективный, пессимистический, когнитивный, неоднозначный, поведенческий, скептический, аффективный, амбивалентный, социальный, психологический, деструктивный, специфический, антисоциальный, гедонистический, противоречивйы, манипулятивный, ценностный, коммуникативный, эмпирический, институциональный."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81834e8-42c6-48f7-a9a0-b491720a7cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_adj_fin = [adj[0][:-4] for adj in pos_adj if adj[0][:-4] not in ['негативный', 'отрицательный', 'субъективный', 'пессимистический', 'когнитивный', 'неоднозначный', 'поведенческий', 'скептический', 'аффективный', 'амбивалентный', 'социальный', 'психологический', 'деструктивный', 'специфический', 'антисоциальный', 'гедонистический', 'противоречивый', 'манипулятивный', 'ценностный', 'коммуникативный', 'эмпирический', 'институциональный']]\n",
    "print(pos_adj_fin)\n",
    "print(len(pos_adj_fin))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277ab0f0-1b19-43a4-a47d-89a40d70757f",
   "metadata": {},
   "source": [
    "Сделаем это с существительными:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1963e83c-9f01-4878-af38-cbd7c9204710",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_noun_sim = model.most_similar('горе_NOUN', topn=100)\n",
    "neg_noun = [sim for sim in neg_noun_sim if sim[0].endswith('NOUN') and sim[1] > 0.5]\n",
    "neg_noun "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d07fe86-2112-45d2-8346-df663b26f19e",
   "metadata": {},
   "source": [
    "Уберем слова радость, утешение, сердце."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e78629-ce35-4c41-bf92-9ae6dac0cb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_noun_fin = [noun[0][:-5] for noun in neg_noun if noun[0][:-5] not in ['радость', 'утешение', 'сердце']]\n",
    "print(neg_noun_fin)\n",
    "print(len(neg_noun_fin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df7578e-5ea4-404b-9551-973dae2c894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_noun_sim = model.most_similar('радость_NOUN', topn=100)\n",
    "pos_noun = [sim for sim in pos_noun_sim if sim[0].endswith('NOUN') and sim[1] > 0.5]\n",
    "#print(pos_noun) #лишние явно печаль, горе, горесть, грусть, скорбь, страдание, тоска, скорба, горечь, огорчение, разочарование, страх, отчаяние\n",
    "pos_noun_fin = [noun[0][:-5] for noun in pos_noun if noun[0][:-5] not in ['печаль', 'горе', 'горесть', 'грусть', 'скорбь', 'страдание', 'тоска', 'скорба', 'горечь', 'огорчение', 'разочарование', 'страх', 'отчаяние']]\n",
    "print(pos_noun_fin)\n",
    "print(len(pos_noun_fin))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997c7890-c962-443c-b7c1-848f50c00787",
   "metadata": {},
   "source": [
    "И наречия:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03f3f11-ac9b-4640-9191-7ab7afbddcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_adv_sim = model.most_similar('позитивно_ADV', topn=100)\n",
    "pos_adv = [sim for sim in pos_adv_sim if sim[0].endswith('ADV') and sim[1] > 0.5]\n",
    "#print(pos_adv) #неоднозначно, критично, негативно, критически, отрицательно, прохладно, нелестно, сдержанно, скептически, пессимистически, противоречиво, неодобрительно, недоброжелательно, нелицеприятно, пренебрежительно, неблагоприятно, недружелюбно, настороженно, своеобразно, трезво\n",
    "pos_adv_fin = [adv[0][:-4] for adv in pos_adv if adv[0][:-4] not in ['неоднозначно', 'критично', 'негативно', 'критически', 'отрицательно', 'прохладно', 'нелестно', 'сдержанно', 'скептически', 'пессимистически', 'противоречиво', 'неодобрительно', 'недоброжелательно', 'нелицеприятно', 'пренебрежительно', 'неблагоприятно', 'недружелюбно', 'настороженно', 'своеобразно']]\n",
    "print(pos_adv_fin)\n",
    "print(len(pos_adv_fin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2069b3d-0b34-4bfb-bd49-d793eaf2c3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_adv_sim = model.most_similar('негативно_ADV', topn=100)\n",
    "neg_adv = [sim for sim in neg_adv_sim if sim[0].endswith('ADV') and sim[1] > 0.5]\n",
    "#print(neg_adv) #положительно, позитивно, благоприятно, благожелательно, сочувственно, нейтрально, лояльно, благосклонно, оптимистически, доброжелательно, оптимистично, положительный, благотворно, серьезно, серьёзно\n",
    "neg_adv_fin = [adv[0][:-4] for adv in neg_adv if adv[0][:-4] not in ['положительно', 'позитивно', 'благоприятно', 'благожелательно', 'сочувственно', 'нейтрально', 'лояльно', 'благосклонно', 'оптимистически', 'доброжелательно', 'оптимистично', 'положительный', 'благотворно', 'серьезно', 'серьёзно']]\n",
    "print(neg_adv_fin)\n",
    "print(len(neg_adv_fin))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4096a89a-fb7f-46d4-8ab9-b1acde7443cf",
   "metadata": {},
   "source": [
    "Этого достаточно! (для серьезной работы нет). В целом посидев один вечер можно собрать вполне презентабельный лексикон на несколько тысяч слов. Сейчас у нас получается следующее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad49b655-6320-4aae-b3ac-e37addb79b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = pos_adj_fin + pos_adv_fin + pos_noun_fin\n",
    "print(len(positive))\n",
    "negative = neg_adj_fin + neg_adv_fin + neg_noun_fin\n",
    "print(len(negative))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17477d79-dd45-45ff-933d-a8b622801a09",
   "metadata": {},
   "source": [
    "Ну что ж. И с меньшим в бой бросались! При этом это не так уж плохо, благодаря векторам можно, приложив некоторые усилия, собрать нюансированный лексикон, подстроенный под определенные отдельные задачи разметки тональности. Посмотрим, что получится на Евгении Онегине."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50bac54-1c9c-4989-b77e-dc55300f1434",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('EugeneOnegin.txt', encoding='utf-8') as txt:\n",
    "    text_orig = txt.read()\n",
    "    corpus = re.split(r'ГЛАВА \\w+\\b', text_orig)\n",
    "    print(len(corpus))\n",
    "    clean_texts = []\n",
    "    just_texts = []\n",
    "    for text in corpus:\n",
    "        text = re.sub(r'\\n', ' ', text)\n",
    "        just_texts.append(text)\n",
    "        text = re.sub('[^а-яА-ЯёЁ -]', '', text.lower())\n",
    "        lemmatized_text = [morph.parse(tok)[0].normal_form for tok in word_tokenize(text)]\n",
    "        text_no_stop = [token for token in lemmatized_text if token not in stopwords_ru]\n",
    "        clean_texts.append(text_no_stop)\n",
    "        \n",
    "print(len(clean_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e774fb-f50e-4f1b-978d-7bf2e67f2da5",
   "metadata": {},
   "source": [
    "Напишем простенький скорер:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2031c8-b1f7-499e-92ca-ca6a6a914e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_scores = []\n",
    "pos_scores = []\n",
    "for text in clean_texts:\n",
    "    neg_score = 0\n",
    "    pos_score = 0\n",
    "    len_t = len(text)\n",
    "    for token in text:\n",
    "        if token in positive:\n",
    "            pos_score += 1\n",
    "        elif token in negative:\n",
    "            neg_score += 1\n",
    "    neg_scores.append(round(neg_score/len_t*100, 2))\n",
    "    pos_scores.append(round(pos_score/len_t*100, 2))\n",
    "\n",
    "print(neg_scores)\n",
    "print(pos_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba51b4e-c737-4975-a46b-b5c271850464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_scorer(corpus):\n",
    "    neg_scores = []\n",
    "    pos_scores = []\n",
    "    for text in corpus:\n",
    "        neg_score = 0\n",
    "        pos_score = 0\n",
    "        len_t = len(text)\n",
    "        for token in text:\n",
    "            if token in positive:\n",
    "               pos_score += 1\n",
    "            elif token in negative:\n",
    "                neg_score += 1\n",
    "        neg_scores.append(round(neg_score/len_t*100, 2))\n",
    "        pos_scores.append(round(pos_score/len_t*100, 2))\n",
    "\n",
    "    return {'pos_score': pos_scores, 'neg_score': neg_scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09214c16-6ca7-476e-b3a3-f73f0ce3f8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = corpus_scorer(clean_texts)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a2d4eb-9d47-48ef-8a5b-3166a9f82b77",
   "metadata": {},
   "source": [
    "Как водится, нанесем на график:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c91140-16f8-419c-b111-8d6dfb15102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters = list(range(1, len(clean_texts) + 1))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(chapters, scores['pos_score'], label='Позитив', color='skyblue', marker='o', linewidth=2)\n",
    "plt.plot(chapters, scores['neg_score'], label='Негатив', color='red', marker='s', linewidth=2)\n",
    "plt.title('Тональность по главам')\n",
    "plt.xlabel('Глава')\n",
    "plt.ylabel('Оценка тональности')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49924a22-dc71-4165-afd7-08aeeae46836",
   "metadata": {},
   "source": [
    "Все это, конечно, ерунда, потому что лексикон очень маленький. Можно попробовать модель сгенерировать лексиконы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e318f56-c030-4864-a845-f36e5c4e2762",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_verbs = ['радовать', 'вдохновлять', 'поддерживать', 'созидать', 'улыбаться', 'любить', 'восхищать', 'помогать', 'воодушевлять', 'творить', 'украшать', 'улучшать', 'развивать', 'согревать', 'заботиться', 'благодарить', 'веселить', 'обнимать', 'дарить', 'делиться', 'светить', 'сиять', 'благоухать', 'процветать', 'гармонизировать', 'укреплять', 'обогащать', 'оживлять', 'возвышать', 'восстанавливать', 'исцелять', 'успокаивать', 'освещать', 'наслаждаться', 'восхищаться', 'мечтать', 'стремиться', 'достигать', 'побеждать', 'преуспевать', 'радоваться', 'ликовать', 'благословлять', 'лелеять', 'хвалить', 'поощрять', 'мотивировать', 'вдохновляться', 'доверять', 'содействовать', 'сближать', 'объединять', 'сплачивать', 'создавать', 'совершенствовать', 'обновлять', 'оживить', 'праздновать', 'улыбать', 'щебетать', 'петь', 'танцевать', 'смеяться', 'шутить', 'играть', 'раскрывать', 'открывать', 'изучать', 'познавать', 'расти', 'цвести', 'усиливать', 'возрождать', 'освежать', 'бодрить', 'тонизировать', 'зажигать', 'вспыхивать', 'сияять', 'блестеть', 'сверкать', 'украшать', 'преображать', 'улучшать', 'вознаграждать', 'ценивать', 'уважать', 'баловать', 'ласкать', 'умилять', 'трогать', 'вдохновлять', 'взлетать', 'парить', 'свободствовать', 'освобождать', 'распускаться', 'расцветать', 'умиротворять', 'согревать', 'защищать']\n",
    "pos_nouns = ['радость', 'счастье', 'любовь', 'доброта', 'успех', 'гармония', 'красота', 'вдохновение', 'тепло', 'свет', 'улыбка', 'дружба', 'мечта', 'надежда', 'сила', 'энергия', 'свобода', 'мир', 'спокойствие', 'блаженство', 'восторг', 'ликование', 'доверие', 'забота', 'нежность', 'ласковость', 'чудо', 'волшебство', 'благодать', 'процветание', 'изобилие', 'творчество', 'совершенство', 'победа', 'триумф', 'гордость', 'честь', 'достоинство', 'уважение', 'благодарность', 'веселье', 'праздник', 'смех', 'игра', 'яркость', 'сияние', 'блеск', 'цвет', 'аромат', 'свежесть', 'жизнь', 'здоровье', 'бодрость', 'энтузиазм', 'оптимизм', 'мотивация', 'цель', 'достижение', 'развитие', 'рост', 'процветание', 'благополучие', 'комфорт', 'уют', 'тепло', 'гостеприимство', 'дружелюбие', 'единство', 'солидарность', 'взаимопонимание', 'поддержка', 'щедрость', 'великодушие', 'терпение', 'мудрость', 'проницательность', 'честность', 'искренность', 'открытость', 'правда', 'справедливость', 'гармония', 'баланс', 'умиротворение', 'безмятежность', 'чистота', 'ясность', 'светозарность', 'возвышенность', 'поэзия', 'музыка', 'танец', 'искра', 'звезда', 'солнце', 'радуга', 'цветок', 'весна', 'жизнерадостность', 'обаяние', 'харизма']\n",
    "pos_adjs = ['радостный', 'счастливый', 'добрый', 'прекрасный', 'вдохновляющий', 'теплый', 'светлый', 'чудесный', 'великолепный', 'удивительный', 'замечательный', 'гармоничный', 'спокойный', 'уверенный', 'яркий', 'душевный', 'искренний', 'дружелюбный', 'восторженный', 'уважительный', 'похвальный', 'трогательный', 'ласковый', 'милый', 'обаятельный', 'энергичный', 'жизнерадостный', 'успешный', 'продуктивный', 'творческий', 'изящный', 'красивый', 'элегантный', 'грациозный', 'мудрый', 'глубокий', 'проницательный', 'честный', 'открытый', 'щедрый', 'великодушный', 'терпеливый', 'справедливый', 'деликатный', 'тактичный', 'внимательный', 'заботливый', 'любовный', 'нежный', 'умиротворенный', 'светлый', 'ясный', 'чистосердечный', 'благородный', 'достойный', 'гордый', 'смелый', 'решительный', 'надежный', 'стабильный', 'безопасный', 'уютный', 'комфортный', 'приятный', 'аппетитный', 'вкусный', 'ароматный', 'свежий', 'бодрый', 'здоровый', 'сильный', 'мощный', 'динамичный', 'увлекательный', 'захватывающий', 'волшебный', 'фантастический', 'необыкновенный', 'оригинальный', 'креативный', 'инновационный', 'прогрессивный', 'эффективный', 'результативный', 'блаженный', 'ликующий', 'восхитительный', 'бесподобный', 'совершенный', 'идеальный', 'возвышенный', 'поэтичный', 'живописный', 'радужный', 'безмятежный', 'умиротворяющий', 'свободный', 'непринужденный', 'естественный', 'плавный', 'утонченный']\n",
    "pos_advs = ['радостно', 'счастливо', 'доброжелательно', 'прекрасно', 'вдохновенно', 'тепло', 'светло', 'чудесно', 'великолепно', 'удивительно', 'замечательно', 'гармонично', 'спокойно', 'уверенно', 'ярко', 'душевно', 'искренне', 'дружелюбно', 'восторженно', 'уважительно', 'похвально', 'трогательно', 'ласково', 'мило', 'обаятельно', 'энергично', 'жизнерадостно', 'успешно', 'продуктивно', 'творчески', 'изящно', 'красиво', 'элегантно', 'грациозно', 'мудро', 'глубоко', 'проницательно', 'честно', 'открыто', 'щедро', 'великодушно', 'терпеливо', 'справедливо', 'деликатно', 'тактично', 'внимательно', 'заботливо', 'любовно', 'нежно', 'умиротворенно', 'ясно', 'чистосердечно', 'благородно', 'достойно', 'гордо', 'смело', 'решительно', 'надежно', 'стабильно', 'безопасно', 'уютно', 'комфортно', 'приятно', 'аппетитно', 'вкусно', 'ароматно', 'свежо', 'бодро', 'здорово', 'сильно', 'мощно', 'динамично', 'увлекательно', 'захватывающе', 'волшебно', 'фантастически', 'необыкновенно', 'оригинально', 'креативно', 'инновационно', 'прогрессивно', 'эффективно', 'результативно', 'блаженно', 'ликующе', 'восхитительно', 'бесподобно', 'совершенно', 'идеально', 'возвышенно', 'поэтично', 'живописно', 'радужно', 'безмятежно', 'умиротворяюще', 'свободно', 'непринужденно', 'естественно', 'плавно', 'утонченно']\n",
    "positives = pos_verbs + pos_nouns + pos_adjs + pos_advs\n",
    "neg_verbs = ['разрушать', 'вредить', 'обманывать', 'оскорблять', 'унижать', 'злиться', 'гневаться', 'кричать', 'ругаться', 'обвинять', 'игнорировать', 'отвергать', 'презирать', 'ненавидеть', 'завидовать', 'мстить', 'угрожать', 'давить', 'подавлять', 'издеваться', 'насмехаться', 'провоцировать', 'конфликтовать', 'ссориться', 'спорить', 'возражать', 'отрицать', 'саботировать', 'мешать', 'затруднять', 'тормозить', 'ограничивать', 'запрещать', 'нарушать', 'портить', 'ломать', 'губить', 'разрушать', 'уничтожать', 'разворовывать', 'красть', 'обворовывать', 'мошенничать', 'лгать', 'фальсифицировать', 'подделывать', 'искажать', 'преувеличивать', 'умалчивать', 'скрывать', 'игнорировать', 'пренебрегать', 'отказывать', 'отталкивать', 'изгонять', 'высмеивать', 'критиковать', 'осуждать', 'порицать', 'упрекать', 'жаловаться', 'ныть', 'ворчать', 'брюзжать', 'раздражать', 'злословить', 'сплетничать', 'клеветать', 'очернять', 'подозревать', 'сомневаться', 'недооценивать', 'переоценивать', 'обесценивать', 'умалять', 'принижать', 'дискриминировать', 'ущемлять', 'ограблять', 'нападать', 'агрессировать', 'драться', 'бить', 'ранить', 'мучить', 'терзать', 'изматывать', 'истощать', 'эксплуатировать', 'шантажировать', 'манипулировать', 'запугивать', 'давить', 'принуждать', 'навязывать', 'обременять', 'засорять', 'загрязнять', 'отравлять', 'разочаровывать', 'подводить']\n",
    "neg_nouns = ['горе', 'печаль', 'страдание', 'тоска', 'грусть', 'скорбь', 'разочарование', 'страх', 'отчаяние', 'гнев', 'злость', 'ненависть', 'зависть', 'месть', 'конфликт', 'ссора', 'обида', 'оскорбление', 'унижение', 'презрение', 'ложь', 'обман', 'предательство', 'измена', 'клевета', 'сплетня', 'злословие', 'насмешка', 'издевательство', 'провокация', 'угроза', 'давление', 'подавление', 'агрессия', 'насилие', 'жестокость', 'мучение', 'боль', 'рана', 'потеря', 'ущерб', 'разрушение', 'хаос', 'беспорядок', 'кризис', 'паника', 'тревога', 'сомнение', 'неуверенность', 'недоверие', 'подозрение', 'злоба', 'раздражение', 'досада', 'огорчение', 'горечь', 'разрушение', 'упадок', 'деградация', 'провал', 'неудача', 'крах', 'банкротство', 'бедствие', 'катастрофа', 'трагедия', 'несчастье', 'беда', 'проблема', 'трудность', 'препятствие', 'ограничение', 'запрет', 'нарушение', 'воровство', 'грабеж', 'мошенничество', 'фальшь', 'подделка', 'искажение', 'ошибка', 'недостаток', 'дефект', 'порок', 'зависимость', 'эксплуатация', 'шантаж', 'манипуляция', 'принуждение', 'дискриминация', 'ущемление', 'несправедливость', 'жесткость', 'равнодушие', 'холодность', 'отчуждение', 'одиночество', 'изоляция', 'безнадежность', 'апатия', 'скука', 'усталость']\n",
    "neg_adjs = ['негативный', 'отрицательный', 'пессимистический', 'скептический', 'деструктивный', 'агрессивный', 'злой', 'гневный', 'враждебный', 'жестокий', 'холодный', 'равнодушный', 'безразличный', 'надменный', 'высокомерный', 'презрительный', 'насмешливый', 'саркастический', 'циничный', 'обидный', 'оскорбительный', 'унизительный', 'грубый', 'хамский', 'вульгарный', 'неприятный', 'отталкивающий', 'отвратительный', 'омерзительный', 'тревожный', 'страшный', 'пугающий', 'мрачный', 'угрюмый', 'печальный', 'грустный', 'тоскливый', 'унылый', 'безрадостный', 'безнадежный', 'отчаянный', 'трагичный', 'горестный', 'болезненный', 'мучительный', 'терзающий', 'изнурительный', 'утомительный', 'скучный', 'монотонный', 'лживый', 'обманный', 'коварный', 'предательский', 'вероломный', 'неискренний', 'фальшивый', 'лицемерный', 'подлый', 'низкий', 'бесчестный', 'непорядочный', 'аморальный', 'безнравственный', 'жесткий', 'суровый', 'неумолимый', 'несправедливый', 'пристрастный', 'предвзятый', 'злопамятный', 'мстительный', 'завистливый', 'жадный', 'скупой', 'эгоистичный', 'корыстный', 'манипулятивный', 'хитрый', 'лукавый', 'скрытный', 'подозрительный', 'недоверчивый', 'трусливый', 'слабый', 'беспомощный', 'ненадежный', 'нестабильный', 'хаотичный', 'беспорядочный', 'разрушительный', 'вредный', 'токсичный', 'опасный', 'угрожающий', 'неблагоприятный', 'неудачный', 'провальный', 'дефектный', 'некачественный', 'неполноценный']\n",
    "neg_advs = ['эгоистично', 'шумно', 'грубо', 'жадно', 'лживо', 'лениво', 'нагло', 'злобно', 'трусливо', 'подло', 'мелочно', 'завистливо', 'высокомерно', 'глупо', 'раздражительно', 'безответственно', 'коварно', 'надменно', 'мерзко', 'лицемерно', 'бестактно', 'вульгарно', 'сварливо', 'мрачно', 'назойливо', 'корыстно', 'апатично', 'безнравственно', 'бездарно', 'бездушно', 'жестоко', 'противно', 'цинично', 'черство', 'упрямо', 'хамовато', 'истерично', 'злопамятно', 'невнимательно', 'неприятно', 'равнодушно', 'тщеславно', 'фальшиво', 'бестолково', 'беспощадно', 'болтливо', 'властно', 'инертно', 'невежественно', 'пугливо', 'агрессивно', 'алчно', 'безалаберно', 'безвольно', 'безрадостно', 'безрассудно', 'беспутно', 'зловеще', 'зловредно', 'болезненно', 'вздорно', 'некомпетентно', 'непослушно', 'непростительно', 'неряшливо', 'несносно', 'нетерпимо', 'нудно', 'обидчиво', 'опасно', 'отвратительно', 'пассивно', 'печально', 'плоско', 'похотливо', 'презрительно', 'пренебрежительно', 'придирающе', 'разрушительно', 'самовлюблённо', 'саркастично', 'свирепо', 'скучно', 'слабо', 'слизко', 'строптиво', 'суеверно', 'угрюмо', 'хаотично', 'холодно', 'негодно', 'недобро', 'недоверчиво', 'нежизнеспособно', 'накладно', 'неверно', 'самонадеянно', 'язвительно', 'безнадёжно', 'уныло']\n",
    "negatives = neg_verbs + neg_nouns + neg_adjs + neg_advs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9ca55f-e066-4675-b4ce-2f589a81961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_scorer_ed(corpus):\n",
    "    neg_scores = []\n",
    "    pos_scores = []\n",
    "    diff_scores = []\n",
    "    for text in corpus:\n",
    "        neg_score = 0\n",
    "        pos_score = 0\n",
    "        len_t = len(text)\n",
    "        for token in text:\n",
    "            if token in positives:\n",
    "               pos_score += 1\n",
    "            elif token in negatives:\n",
    "                neg_score += 1\n",
    "        neg_scores.append(round(neg_score/len_t*100, 2))\n",
    "        pos_scores.append(round(pos_score/len_t*100, 2))\n",
    "        diff_scores.append(round(pos_score/len_t*100 - neg_score/len_t*100, 2)) #добавим разницу\n",
    "    \n",
    "    return {'pos_score': pos_scores, 'neg_score': neg_scores, 'pos_neg': diff_scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f78dd0-69fd-4cc7-813c-146c2aa89414",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = corpus_scorer_ed(clean_texts)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834fbf3a-e132-4523-a354-39d3a3b58281",
   "metadata": {},
   "source": [
    "С новым списком долги негативных и позитивных явно выросли. При этом в целом Евгений Онегин остается все еще более позитивным текстом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3619de8-cc69-4852-bf5b-8d71d54f51a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters = list(range(1, len(clean_texts) + 1))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(chapters, scores['pos_score'], label='Позитив', color='skyblue', marker='o', linewidth=2)\n",
    "plt.plot(chapters, scores['neg_score'], label='Негатив', color='red', marker='s', linewidth=2)\n",
    "plt.plot(chapters, scores['pos_neg'], label='Позитив-негатив', color='green', marker='^', linewidth=2)\n",
    "plt.title('Тональность по главам')\n",
    "plt.xlabel('Глава')\n",
    "plt.ylabel('Оценка тональности')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a6056c-0f8d-4271-b62f-f240eb006103",
   "metadata": {},
   "source": [
    "Можно интерпретировать данные в графиках по-другому. Например, показать долю эмоциональных слов в целом, а не разницу (позже добавим в наш скорер):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50f9898-601a-4720-ba2a-5387fd8cc0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = []\n",
    "for index in range(len(scores['pos_score'])):\n",
    "    #print(scores['pos_score'][index] + scores['neg_score'][index])\n",
    "    emotions.append(scores['pos_score'][index] + scores['neg_score'][index])\n",
    "print(emotions)\n",
    "\n",
    "#то же самое\n",
    "emotions = [scores['pos_score'][index] + scores['neg_score'][index] for index in range(len(scores['pos_score']))]\n",
    "print(emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef520ce-c13c-45f5-b482-055e566a2261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_scorer_ed(corpus):\n",
    "    neg_scores = []\n",
    "    pos_scores = []\n",
    "    diff_scores = []\n",
    "    num_tokens = []\n",
    "    num_pos = []\n",
    "    num_neg = []\n",
    "    for text in corpus:\n",
    "        neg_score = 0\n",
    "        pos_score = 0\n",
    "        len_t = len(text)\n",
    "        for token in text:\n",
    "            if token in positives:\n",
    "               pos_score += 1\n",
    "            elif token in negatives:\n",
    "                neg_score += 1\n",
    "        neg_scores.append(round(neg_score/len_t*100, 2))\n",
    "        pos_scores.append(round(pos_score/len_t*100, 2))\n",
    "        diff_scores.append(round(pos_score/len_t*100 - neg_score/len_t*100, 2)) #добавим разницу\n",
    "        num_tokens.append(len_t)\n",
    "        num_pos.append(pos_score)\n",
    "        num_neg.append(neg_score)\n",
    "    return {'pos_score': pos_scores, 'neg_score': neg_scores, 'pos_neg': diff_scores,\n",
    "           'num_tokens': num_tokens, 'num_pos': num_pos, 'num_neg': num_neg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e019ff4-af14-41ba-b13b-5da8bab0efb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = corpus_scorer_ed(clean_texts)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0006f1a1-9b10-4f79-a988-a8d3a145d467",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters = list(range(1, len(clean_texts) + 1))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(chapters, emotions, label='Эмоциональные слова', color='skyblue', marker='o', linewidth=2)\n",
    "plt.title('Эмоциональность по главам, в %')\n",
    "plt.xlabel('Глава')\n",
    "plt.ylabel('Оценка тональности')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a45e8d6-5ca8-4d02-926b-ce18fc53fca9",
   "metadata": {},
   "source": [
    "Отобразим сумму эмоциональных слов на фоне всех слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad15e76-8b68-4b4b-a44d-25e8c77f93f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_sum = [scores['num_pos'][index] + scores['num_neg'][index] for index in range(len(scores['pos_score']))]\n",
    "print(emotions_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9690e00-be29-48ed-a58f-6315f762f0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(chapters, scores['num_tokens'], color='gray', label='Всего слов', alpha=0.3)\n",
    "plt.bar(chapters, emotions_sum, color='red', label='Всего эмоциональных слов', alpha=0.3)\n",
    "plt.xlabel('Глава')\n",
    "plt.ylabel('Количество слов')\n",
    "plt.title('Драматичный график суммы слов')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72de6ce-c59a-408d-9f9e-d6db6b299281",
   "metadata": {},
   "source": [
    "Ну и наконец готовые лексиконы. Они обычно намного крупнее и мощнее тех игрушек, которые мы попробовали сделать сами."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9485f735-33e4-44ac-aa78-1b68f1a029ae",
   "metadata": {},
   "source": [
    "Воспользуемся русентилексом: https://www.labinform.ru/pub/rusentilex/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c77717-31ff-4eea-8ec4-88669587a4fd",
   "metadata": {},
   "source": [
    "!Словарь РуСентиЛекс  \n",
    "! Структура:   \n",
    "! 1. слово или словосочетание,  \n",
    "! 2. Часть речи или синтаксический тип группы,  \n",
    "! 3. слово или словосочетание в лемматизированной форме,   \n",
    "! 4. Тональность: позитивная (positive), негативная(negative), нейтральная (neutral) или неопределеная   оценка, зависит от контекста (positive/negative),  \n",
    "! 5. Источник: оценка (opinion), чувство (feeling), факт (fact),  \n",
    "! 6. Если тональность отличается для разных значений многозначного слова, то перечисляются все значения слова по тезаурусу РуТез и дается отсылка на сооветствующее понятие - имя понятия в кавычках.\n",
    "!  \n",
    "!RuSentiLex Structure  \n",
    "!1. word or phrase,  \n",
    "!2. part of speech or type of syntactic group,  \n",
    "!3. initial word (phrase) in a lemmatized form,  \n",
    "!4. Sentiment: positive, negative, neutral or positive/negative (indefinite, depends on the context),  \n",
    "!5. Source: opinion, feeling (private state), or fact (sentiment connotation),  \n",
    "!6. Ambiguity: if sentiment is different for senses of an ambiguous word, then sentiment orientations for all senses are described, the senses  \n",
    "!are labeled with the RuThes concept names.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986185de-202f-4421-9c96-cc9fe6be4f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rusentilex_2017.txt', encoding='utf-8') as txt:\n",
    "    text = txt.read()\n",
    "    print(text[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250c7976-2865-4b20-ad36-54a111621c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = text.split('\\n')\n",
    "lines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaf7979-9176-416b-a4f1-f1da44b5ffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_lex = []\n",
    "for line in lines:\n",
    "    line_s = line.split(',')\n",
    "    try:\n",
    "        if line_s[3].strip() == 'positive':\n",
    "            pos_lex.append(line_s[0])\n",
    "    except IndexError:\n",
    "        continue\n",
    "print(pos_lex[:10])\n",
    "print(len(pos_lex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9ece4b-7c00-47ce-adc3-1bcb7f4434c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_lex = []\n",
    "for line in lines:\n",
    "    line_s = line.split(',')\n",
    "    try:\n",
    "        if line_s[3].strip() == 'negative':\n",
    "            neg_lex.append(line_s[0])\n",
    "    except IndexError:\n",
    "        continue\n",
    "print(neg_lex[:10])\n",
    "print(len(neg_lex))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b90964-e13f-4368-80ff-1bd7c7e293d2",
   "metadata": {},
   "source": [
    " Немного изменим скорер:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c229b926-df03-44a9-9b5d-ce8ad8824625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_scorer_ed(corpus):\n",
    "    neg_scores = []\n",
    "    pos_scores = []\n",
    "    diff_scores = []\n",
    "    num_tokens = []\n",
    "    num_pos = []\n",
    "    num_neg = []\n",
    "    for text in corpus:\n",
    "        neg_score = 0\n",
    "        pos_score = 0\n",
    "        len_t = len(text)\n",
    "        for token in text:\n",
    "            if token in pos_lex:\n",
    "               pos_score += 1\n",
    "            elif token in neg_lex:\n",
    "                neg_score += 1\n",
    "        neg_scores.append(round(neg_score/len_t*100, 2)) \n",
    "        pos_scores.append(round(pos_score/len_t*100, 2)) \n",
    "        diff_scores.append(round(pos_score/len_t*100 - neg_score/len_t*100, 2)) #добавим разницу\n",
    "        num_tokens.append(len_t)\n",
    "        num_pos.append(pos_score)\n",
    "        num_neg.append(neg_score)\n",
    "    return {'pos_score': pos_scores, 'neg_score': neg_scores, 'pos_neg': diff_scores,\n",
    "           'num_tokens': num_tokens, 'num_pos': num_pos, 'num_neg': num_neg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a5bb52-90a0-41e9-ba23-97ace33a0986",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = corpus_scorer_ed(clean_texts)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946bf1e1-4b2b-4647-a0f3-6253691d5b45",
   "metadata": {},
   "source": [
    "Кажется, скоры явно прояснились. Мы уже видим падение разницы пос-нег в негативную зону в той части, где происходят убийства, грусть и расставания. Ура!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6535b7-b31a-4b6c-8ddf-a2cd785681f0",
   "metadata": {},
   "source": [
    "Нарисуем разные графики снова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de25e5ad-b68b-4dfb-b981-b6a1abeef3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters = list(range(1, len(clean_texts) + 1))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(chapters, scores['pos_score'], label='Позитив', color='skyblue', marker='o', linewidth=2)\n",
    "plt.plot(chapters, scores['neg_score'], label='Негатив', color='red', marker='s', linewidth=2)\n",
    "plt.title('Тональность по главам')\n",
    "plt.xlabel('Глава')\n",
    "plt.ylabel('Оценка тональности')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42cd3fc-a382-44ec-a627-8926d0e979fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters = list(range(1, len(clean_texts) + 1))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(chapters, emotions, label='Эмоциональные слова', color='skyblue', marker='o', linewidth=2)\n",
    "plt.title('Общая эмоциональность по главам, в %')\n",
    "plt.xlabel('Глава')\n",
    "plt.ylabel('Оценка тональности')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f809e1-4fe6-4387-abef-5e13aa9a35d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters = list(range(1, len(clean_texts) + 1))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(chapters, scores['pos_neg'], label='Позитив-негатив', color='green', marker='*', linewidth=2)\n",
    "plt.title('Превалирование позитивных и негативных слов')\n",
    "plt.xlabel('Глава')\n",
    "plt.ylabel('Оценка тональности')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b929dd3a-6efc-4610-8312-721755ec9970",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_sum = [scores['num_pos'][index] + scores['num_neg'][index] for index in range(len(scores['pos_score']))]\n",
    "print(emotions_sum)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(chapters, scores['num_tokens'], color='gray', label='Всего слов', alpha=0.3)\n",
    "plt.bar(chapters, emotions_sum, color='red', label='Всего эмоциональных слов', alpha=0.3)\n",
    "plt.xlabel('Глава')\n",
    "plt.ylabel('Количество слов')\n",
    "plt.title('Драматичный график суммы слов')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebff6838-81ff-44d9-af37-b7a0349fff0b",
   "metadata": {},
   "source": [
    "**Задание 1.** Исследуйте с помощью нашего эмоционального скорера любой роман Достоевского. Видны ли там изменения по главам? Предобработайте роман, если нужно. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce2f5a5-394c-45ee-9daf-4f258a7d0735",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c965dd-1d77-4692-b04a-63a5414af20f",
   "metadata": {},
   "source": [
    "**Задание 2.** Как поменять обработку лексикона, чтобы она вывела вам не эмоциональные слова, а типы источников: факты, мнения или чувства. Выведите графики для таких типов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be017a1-ef59-4976-8602-8a13dd947d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a2f940-199b-472a-a256-cafc4dcf5872",
   "metadata": {},
   "source": [
    "Давайте еще посмотрим, как описывается Москва в каждой из глав."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f6f7df-cf3a-4f94-bea5-f0f081aaf963",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tat = []\n",
    "for text in clean_texts:\n",
    "    chap_context = []\n",
    "    for index in range(len(text)):\n",
    "        if text[index] == 'татьяна':  \n",
    "            start = max(0, index - 5) \n",
    "            end = min(len(text), index + 5 + 1) \n",
    "            context = ' '.join(text[start:end])  \n",
    "            chap_context.append(context)\n",
    "    tat.append(' '.join(chap_context))\n",
    "        \n",
    "eug = []\n",
    "for text in clean_texts:\n",
    "    chap_context = []\n",
    "    for index in range(len(text)):\n",
    "        if text[index] == 'евгений':  \n",
    "            start = max(0, index - 5) \n",
    "            end = min(len(text), index + 5 + 1) \n",
    "            context = ' '.join(text[start:end])  \n",
    "            chap_context.append(context)\n",
    "    eug.append(' '.join(chap_context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f71eda9-f646-4524-8d15-352181720469",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tat)\n",
    "prunt(eug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4438d27-e5ac-4050-9ecb-6b302bbdf70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_scorer_ed(tat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddfa760-87fc-4a62-89d3-a9f6ac64a938",
   "metadata": {},
   "source": [
    "Немного подлатаем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933d13fc-2cbc-4aa7-aa1b-077e9a791ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_scorer_ed_nuance(corpus):\n",
    "    neg_scores = []\n",
    "    pos_scores = []\n",
    "    diff_scores = []\n",
    "    num_tokens = []\n",
    "    num_pos = []\n",
    "    num_neg = []\n",
    "    for text in corpus:\n",
    "        neg_score = 0\n",
    "        pos_score = 0\n",
    "        len_t = len(word_tokenize(text))\n",
    "        for token in word_tokenize(text):\n",
    "            if token in pos_lex:\n",
    "               pos_score += 1\n",
    "            elif token in neg_lex:\n",
    "                neg_score += 1\n",
    "        if len_t != 0:\n",
    "            neg_scores.append(round(neg_score/len_t*100, 2)) \n",
    "            pos_scores.append(round(pos_score/len_t*100, 2)) \n",
    "            diff_scores.append(round(pos_score/len_t*100 - neg_score/len_t*100, 2)) #добавим разницу\n",
    "            num_tokens.append(len_t)\n",
    "            num_pos.append(pos_score)\n",
    "            num_neg.append(neg_score)\n",
    "        else:\n",
    "            neg_scores.append(0) \n",
    "            pos_scores.append(0) \n",
    "            diff_scores.append(0) #добавим разницу\n",
    "            num_tokens.append(len_t)\n",
    "            num_pos.append(pos_score)\n",
    "            num_neg.append(neg_score)\n",
    "            \n",
    "    return {'pos_score': pos_scores, 'neg_score': neg_scores, 'pos_neg': diff_scores,\n",
    "           'num_tokens': num_tokens, 'num_pos': num_pos, 'num_neg': num_neg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bf4fec-3ddf-4a3c-88fe-50bcbd0e3168",
   "metadata": {},
   "outputs": [],
   "source": [
    "tat_count = corpus_scorer_ed_nuance(tat)\n",
    "eug_count = corpus_scorer_ed_nuance(eug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355d9ac6-c9cc-4319-ac7f-a2cc1fcaaffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters = list(range(1, len(clean_texts) + 1))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(chapters, tat_count['pos_neg'], label='Позитив-негатив Татьяны', color='skyblue', marker='*', linewidth=2)\n",
    "plt.plot(chapters, eug_count['pos_neg'], label='Позитив-негатив Евгения', color='tomato', marker='s', linewidth=2)\n",
    "\n",
    "for i, (tat_val, eug_val) in enumerate(zip(tat_count['pos_neg'], eug_count['pos_neg'])):\n",
    "    plt.text(chapters[i], tat_val + 0.5, f'{tat_val:.2f}', ha='left', va='bottom', fontsize=11, color='skyblue')\n",
    "    plt.text(chapters[i], eug_val - 0.7, f'{eug_val:.2f}', ha='left', va='top', fontsize=11, color='tomato')\n",
    "\n",
    "plt.title('Превалирование позитивных и негативных слов')\n",
    "plt.xlabel('Глава')\n",
    "plt.ylabel('Оценка тональности')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c0d8af-e88b-4dda-9219-876448d83aed",
   "metadata": {},
   "source": [
    "**Задание 3**. Посмотрите снова в текст Достоевского. Попробуйте поисследовать тональность вокруг определенного объекта или персонажа (деньги, Раскольников, истина, Бог...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b0e0ad-6e1c-4791-82f2-a3d4a30e9799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7023e4-72bf-472f-a18b-4d573930928e",
   "metadata": {},
   "source": [
    "Нейронные сети и здесь нам могут помочь. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4b2bd2-09b6-4425-8581-0d9edbb6acb3",
   "metadata": {},
   "source": [
    "Воспользуемся ruBERT. Используем blanchefort/rubert-base-cased-sentiment-rusentiment: https://huggingface.co/blanchefort/rubert-base-cased-sentiment.  \n",
    "\n",
    "А для английского можно использовать NRClex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22490866-1f2f-42d9-a4f3-58b2fa2aaba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#не забудьте установить библиотеки, если у вас их нет\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dead3482-3415-4870-b096-aa858727e3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('blanchefort/rubert-base-cased-sentiment')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('blanchefort/rubert-base-cased-sentiment', return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f53f96e-12a7-477b-8e21-7115eaf25368",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Виды меток:\", model.config.id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c72f95c-1bad-47db-abc0-91c76a095c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    inputs = tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "    outputs = model(**inputs)\n",
    "    predicted = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "    predicted = torch.argmax(predicted, dim=1).numpy()\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fde5ea9-9174-4067-9f66-08af68123289",
   "metadata": {},
   "source": [
    "Предсказание идет по всем текстам: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42b2e62-995b-42b8-804e-f03ee26e1948",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Этот фильм просто замечательный!\",\n",
    "    \"Мне не понравился этот ресторан.\",\n",
    "    \"Сегодня обычный день, ничего особенного.\"\n",
    "]\n",
    "for text in texts:\n",
    "    print(f\"Предсказание для '{text}': {predict(text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfa074c-3f0a-47db-9239-464e9a4b3e9c",
   "metadata": {},
   "source": [
    "Посмотрим на главы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6703dd6-7936-42f5-836b-9d7ac29f9daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_texts_j = [' '.join(text) for text in clean_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c61730-cc73-4d58-a374-5936af9dc634",
   "metadata": {},
   "outputs": [],
   "source": [
    "chap_count = 1\n",
    "bert_emotions = []\n",
    "for text in clean_texts_j:\n",
    "    prediction = predict(text)\n",
    "    print(f\"Предсказание для главы '{chap_count}': {prediction}\")\n",
    "    bert_emotions.append(predict(text))\n",
    "    chap_count += 1\n",
    "\n",
    "print(bert_emotions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093cae70-2ae7-434b-af83-90ddbabd25e2",
   "metadata": {},
   "source": [
    "Изменим метки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056dcc1c-1364-4922-af4e-ccd8dfce4831",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emotions = []\n",
    "for emo in bert_emotions:\n",
    "    if str(emo) == '[1]':\n",
    "        word_emotions.append('Позитив')\n",
    "    elif str(emo) == '[2]':\n",
    "        word_emotions.append('Негатив')\n",
    "    else:\n",
    "        word_emotions.append('Нейтральность')\n",
    "\n",
    "word_emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b0bd26-2b07-44ae-91e1-4abcce20cf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters = list(range(1, len(clean_texts) + 1))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(chapters, word_emotions, label='Эмоциональные слова', color='tomato', marker='o', linewidth=2)\n",
    "plt.title('Общая эмоциональность по главам, оценка')\n",
    "plt.xlabel('Глава')\n",
    "plt.ylabel('Оценка тональности')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58aee00-6741-4306-9c35-dd5f8e780833",
   "metadata": {},
   "source": [
    "Решение по главам. Переделаем в гистограмму: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c442aa96-7451-4522-a976-c4b2580ed6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "#plt.bar(list(Counter(word_emotions).keys()), list(Counter(word_emotions).values()), color=['tomato', 'steelblue', 'crimson'])\n",
    "bars = plt.bar(list(Counter(word_emotions).keys()), list(Counter(word_emotions).values()), color=['tomato', 'steelblue', 'crimson'])\n",
    "plt.title('Общая эмоциональность по главам')\n",
    "plt.legend(bars, list(Counter(word_emotions).keys()), title=\"Настроение\", loc=\"best\")\n",
    "plt.xlabel('Настроение')\n",
    "plt.ylabel('Количество')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1170fd50-b6f5-4bf5-bc35-5ddd68ce279d",
   "metadata": {},
   "source": [
    "И круговую:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b6643f-5de8-478f-9547-1a429e598eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.pie(list(Counter(word_emotions).values()), labels=list(Counter(word_emotions).values()), colors=['tomato', 'steelblue', 'crimson'])\n",
    "plt.title('Общая эмоциональность по главам')\n",
    "plt.legend(list(Counter(word_emotions).keys()), title=\"Настроение\", loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba635146-0d20-49aa-a615-dbf53035d243",
   "metadata": {},
   "source": [
    "А если не по предобработанным текстам? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91049a8c-39d5-4aca-83fc-a840339b2b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chap_counter = 1\n",
    "for text in just_texts:\n",
    "    prediction = predict(text)\n",
    "    print(f\"Предсказание для главы '{chap_counter}': {prediction}\")\n",
    "    chap_counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f746b61a-1f86-4a57-9928-19d19ca0439f",
   "metadata": {},
   "source": [
    "Вгоняет в депрессию."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c004ac-ef4b-4d71-a800-726f1937edb8",
   "metadata": {},
   "source": [
    "**Задание 3**. Попробуйте разметить главы в тексте Достоевского и визуализировать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a620d561-1390-4161-847e-d809f7d7828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c03164a-9a25-44c8-b729-5a2eb50670a2",
   "metadata": {},
   "source": [
    "**Задание 4.** Перепишите процесс предсказания так, чтобы он размечал по предложениям и выводил среднее арифметическое оценки по главе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afb74c6-2c72-4826-98f6-b17a5c09c475",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
